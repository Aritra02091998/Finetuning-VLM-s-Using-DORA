{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e659ee3-10d7-4ebc-abac-b4ee8470a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3374451-09a7-46e1-a8c6-52bbffc47be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f003fa7-026c-4d65-bd17-f0c74ccf28f1",
   "metadata": {},
   "source": [
    "### Set up Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eab4d83-b5dc-450f-b6ca-567f00eb1d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 04:55:30,137 - INFO - Logging is set up in the notebook!\n"
     ]
    }
   ],
   "source": [
    "# Clear previous handlers to avoid duplicate logs in Jupyter\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Change to DEBUG for more verbosity\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]  # Ensures it logs to Jupyter cell output\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Logging is set up in the notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3307cc-4cf7-4b17-8d3b-679e5967e1e8",
   "metadata": {},
   "source": [
    "### Load the MultiDomain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1ac302-2136-4087-87cb-44b49459e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Generate a one word or single number answer for the given image and question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411f9acb-e6e4-49ab-b32a-408de047911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_prefix(example):\n",
    "    example['question'] = prefix + ': ' + example['question']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c830af57-c6bc-4e30-8687-9fe8a419f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dutta18/multi-domain-VQA-1.5K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21dd337-23a8-4b4d-9cf8-8ebba5956ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = dataset['train'], dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e1e9cd0-2e4c-410b-b741-9f97feb0c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.map(prepend_prefix)\n",
    "val_set = val_set.map(prepend_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087b7d0-c8a9-4f52-a05d-8631f1d19f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71a3368-7204-4102-a07a-cc322b9e9e61",
   "metadata": {},
   "source": [
    "### Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b250f0d-0573-4b03-bf58-f543077b19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cfb6e80-4763-4358-89fd-bb07e42a0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import PaliGemmaProcessor, PaliGemmaForConditionalGeneration, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2bb311-d744-4af9-8505-7db8cf157057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/paligemma-3b-pt-224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed4419-2fef-4dfc-bf81-24c97ac39f46",
   "metadata": {},
   "source": [
    "### Intialize Quantisation Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df1a5716-11ca-4be5-b2b0-854b570c83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,  \n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for memory savings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db59af-4cca-4f35-a2e4-361831305a22",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc1ce55-a1d4-477a-b6d7-42a705b73d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1c7fd5dc3242578b3bb5c38d486ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config = bnb_config, \n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    torch_dtype = torch.float16, \n",
    "    device_map = 'auto'\n",
    ")\n",
    "\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383dc44e-4c72-4875-80d6-b85b9948a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token = processor.tokenizer.convert_tokens_to_ids(\"<image>\")\n",
    "bos_token = processor.tokenizer.convert_tokens_to_ids(\"<bos>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b1441-fd8f-42d1-82f0-5aafb404b88f",
   "metadata": {},
   "source": [
    "### Intialize DORA Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c809394-2dfd-412b-a9a9-ea2e3c7dcb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dora_config = LoraConfig(\n",
    "    r = 16,\n",
    "    lora_alpha = 16*2,       # Scaling factor\n",
    "    lora_dropout = 0.05,     # Dropout rate\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\",  \"o_proj\", \"out_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    use_dora = True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92c2f0aa-fa3c-4646-b153-60d0a7f06f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "quantized_dora_base_model = get_peft_model(base_model, dora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c6b1c-b093-4083-b9d3-0e7d5ed2fe3c",
   "metadata": {},
   "source": [
    "### Calculate Number of Params: ~ 24.4 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f40e47b-f88b-4e3b-9a31-884b9dda9de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_trainable_params():\n",
    "    \n",
    "    # Simple param report\n",
    "    trainable = sum(p.numel() for p in quantized_dora_base_model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable params: {trainable/1e6:.1f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd22ade3-304e-4c96-b7cd-8525b0a31df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params: 24.4 M\n"
     ]
    }
   ],
   "source": [
    "report_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad288774-b774-4a4e-9553-f8a9d8d00df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2276ea8c-f829-4206-bf95-7641e8f9c8a4",
   "metadata": {},
   "source": [
    "### Setting Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf3633f0-b001-4b24-ae64-16e56a906db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    texts = [\n",
    "        f\"<image> <bos> answer {example['question']}\" for example in examples\n",
    "    ]  \n",
    "    labels = [example['answer'] for example in examples]\n",
    "    images = [example[\"image\"].convert(\"RGB\") for example in examples]\n",
    "\n",
    "    tokens = processor(text=texts, images=images, suffix=labels, return_tensors=\"pt\", padding=\"longest\")\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "    tokens[\"pixel_values\"] = tokens[\"pixel_values\"].to(torch.bfloat16)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a42b76f-e8b1-455f-8660-1241aab3485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize_ = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bcefa8e-e561-4b6f-9f57-5ee196876ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batchSize_, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=batchSize_, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3b7e4-a5cf-42a2-ae16-737dba214980",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87b9be5d-b9d5-44fb-af7d-07b3162e6ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def do_validation():\n",
    "    quantized_dora_base_model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "        \n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            outputs = quantized_dora_base_model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    torch.cuda.empty_cache()\n",
    "    quantized_dora_base_model.train()\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63411a-a010-4587-b1ba-6dc49f8ff51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84ec0427-94cd-4010-a4b8-f4a3b9b9f63e",
   "metadata": {},
   "source": [
    "### Training Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0de21db6-c8ed-4818-b76b-23027e42455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55f4a804-b801-47ab-8922-16d3c9d60c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "weight_decay = 0.001\n",
    "learning_rate = 5e-4\n",
    "gradient_accumulation_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "159a43fa-8798-4148-8bf0-2b0b98abdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(quantized_dora_base_model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e6848f4-edf5-4852-8f01-aa0fb020358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_steps = len(train_loader) // gradient_accumulation_steps * epochs\n",
    "warmup_steps = int(0.05 * total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "734333d6-e449-4eec-8b74-45e48d19c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 46\n"
     ]
    }
   ],
   "source": [
    "print(total_train_steps, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb20a380-f483-4db6-9040-335b296abdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "134beb14-fc78-468d-8234-346533214d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "quantized_dora_base_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ffa8df0-6fc4-4d05-a587-55535b0683f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = quantized_dora_base_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01323510-f846-4434-86f6-d48289aed92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir = '/home/aritrad/main/PaliGemma-3B/MOE/Multidomain/chkpts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4601a3-eed9-4d31-9dbf-58584f1d1afb",
   "metadata": {},
   "source": [
    "## Native PyTorch Training Loop\n",
    "\n",
    "##### I am using val_loss as the checkpointing criteria, but any other metric which test text generation quality can be used here.\n",
    "\n",
    "##### MAX GPU USAGE = 24 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36fab0-407f-4505-a7e8-278473ed0b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a930727b774b3990bed43d5bf567bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aritrad/miniconda3/envs/stable_env/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/aritrad/miniconda3/envs/stable_env/lib/python3.9/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "2025-07-08 04:57:17,701 - INFO - [Epoch 1 | Idx: 1 | Optim Step: 1 | Loss: 2.4060]\n",
      "2025-07-08 04:57:20,984 - INFO - [Epoch 1 | Idx: 3 | Optim Step: 2 | Loss: 1.5784]\n",
      "2025-07-08 04:57:24,273 - INFO - [Epoch 1 | Idx: 5 | Optim Step: 3 | Loss: 2.1227]\n",
      "2025-07-08 04:57:27,574 - INFO - [Epoch 1 | Idx: 7 | Optim Step: 4 | Loss: 1.7689]\n",
      "2025-07-08 04:57:30,866 - INFO - [Epoch 1 | Idx: 9 | Optim Step: 5 | Loss: 1.1190]\n",
      "2025-07-08 04:57:34,135 - INFO - [Epoch 1 | Idx: 11 | Optim Step: 6 | Loss: 2.5022]\n",
      "2025-07-08 04:57:37,397 - INFO - [Epoch 1 | Idx: 13 | Optim Step: 7 | Loss: 2.4106]\n",
      "2025-07-08 04:57:40,672 - INFO - [Epoch 1 | Idx: 15 | Optim Step: 8 | Loss: 2.0931]\n",
      "2025-07-08 04:57:43,963 - INFO - [Epoch 1 | Idx: 17 | Optim Step: 9 | Loss: 1.7350]\n",
      "2025-07-08 04:57:47,221 - INFO - [Epoch 1 | Idx: 19 | Optim Step: 10 | Loss: 1.0874]\n",
      "2025-07-08 04:57:50,512 - INFO - [Epoch 1 | Idx: 21 | Optim Step: 11 | Loss: 1.0917]\n",
      "2025-07-08 04:57:53,805 - INFO - [Epoch 1 | Idx: 23 | Optim Step: 12 | Loss: 1.0326]\n",
      "2025-07-08 04:57:57,055 - INFO - [Epoch 1 | Idx: 25 | Optim Step: 13 | Loss: 1.3009]\n",
      "2025-07-08 04:58:00,314 - INFO - [Epoch 1 | Idx: 27 | Optim Step: 14 | Loss: 0.6578]\n",
      "2025-07-08 04:58:03,575 - INFO - [Epoch 1 | Idx: 29 | Optim Step: 15 | Loss: 0.3691]\n",
      "2025-07-08 04:58:06,840 - INFO - [Epoch 1 | Idx: 31 | Optim Step: 16 | Loss: 0.3827]\n",
      "2025-07-08 04:58:10,107 - INFO - [Epoch 1 | Idx: 33 | Optim Step: 17 | Loss: 1.3394]\n",
      "2025-07-08 04:58:13,418 - INFO - [Epoch 1 | Idx: 35 | Optim Step: 18 | Loss: 0.8526]\n",
      "2025-07-08 04:58:16,673 - INFO - [Epoch 1 | Idx: 37 | Optim Step: 19 | Loss: 0.5096]\n",
      "2025-07-08 04:58:19,982 - INFO - [Epoch 1 | Idx: 39 | Optim Step: 20 | Loss: 2.0663]\n",
      "2025-07-08 04:58:23,244 - INFO - [Epoch 1 | Idx: 41 | Optim Step: 21 | Loss: 0.7705]\n",
      "2025-07-08 04:58:26,543 - INFO - [Epoch 1 | Idx: 43 | Optim Step: 22 | Loss: 0.7616]\n",
      "2025-07-08 04:58:29,872 - INFO - [Epoch 1 | Idx: 45 | Optim Step: 23 | Loss: 1.0438]\n",
      "2025-07-08 04:58:33,213 - INFO - [Epoch 1 | Idx: 47 | Optim Step: 24 | Loss: 1.8044]\n",
      "2025-07-08 04:58:36,506 - INFO - [Epoch 1 | Idx: 49 | Optim Step: 25 | Loss: 0.7024]\n",
      "2025-07-08 04:58:39,760 - INFO - [Epoch 1 | Idx: 51 | Optim Step: 26 | Loss: 0.7419]\n",
      "2025-07-08 04:58:43,048 - INFO - [Epoch 1 | Idx: 53 | Optim Step: 27 | Loss: 1.2045]\n",
      "2025-07-08 04:58:46,318 - INFO - [Epoch 1 | Idx: 55 | Optim Step: 28 | Loss: 0.8013]\n",
      "2025-07-08 04:58:49,662 - INFO - [Epoch 1 | Idx: 57 | Optim Step: 29 | Loss: 2.5387]\n",
      "2025-07-08 04:58:52,932 - INFO - [Epoch 1 | Idx: 59 | Optim Step: 30 | Loss: 0.2323]\n",
      "2025-07-08 04:58:56,214 - INFO - [Epoch 1 | Idx: 61 | Optim Step: 31 | Loss: 1.1816]\n",
      "2025-07-08 04:58:59,523 - INFO - [Epoch 1 | Idx: 63 | Optim Step: 32 | Loss: 1.9013]\n",
      "2025-07-08 04:59:02,822 - INFO - [Epoch 1 | Idx: 65 | Optim Step: 33 | Loss: 1.0805]\n",
      "2025-07-08 04:59:06,127 - INFO - [Epoch 1 | Idx: 67 | Optim Step: 34 | Loss: 0.9479]\n",
      "2025-07-08 04:59:09,421 - INFO - [Epoch 1 | Idx: 69 | Optim Step: 35 | Loss: 0.8938]\n",
      "2025-07-08 04:59:12,671 - INFO - [Epoch 1 | Idx: 71 | Optim Step: 36 | Loss: 0.9536]\n",
      "2025-07-08 04:59:15,951 - INFO - [Epoch 1 | Idx: 73 | Optim Step: 37 | Loss: 0.5456]\n",
      "2025-07-08 04:59:19,191 - INFO - [Epoch 1 | Idx: 75 | Optim Step: 38 | Loss: 0.5939]\n",
      "2025-07-08 04:59:22,458 - INFO - [Epoch 1 | Idx: 77 | Optim Step: 39 | Loss: 1.3586]\n",
      "2025-07-08 04:59:25,735 - INFO - [Epoch 1 | Idx: 79 | Optim Step: 40 | Loss: 1.2179]\n",
      "2025-07-08 04:59:29,052 - INFO - [Epoch 1 | Idx: 81 | Optim Step: 41 | Loss: 1.5807]\n",
      "2025-07-08 04:59:32,288 - INFO - [Epoch 1 | Idx: 83 | Optim Step: 42 | Loss: 0.6772]\n",
      "2025-07-08 04:59:35,548 - INFO - [Epoch 1 | Idx: 85 | Optim Step: 43 | Loss: 1.2518]\n",
      "2025-07-08 04:59:38,853 - INFO - [Epoch 1 | Idx: 87 | Optim Step: 44 | Loss: 0.7151]\n",
      "2025-07-08 04:59:42,151 - INFO - [Epoch 1 | Idx: 89 | Optim Step: 45 | Loss: 0.4139]\n",
      "2025-07-08 04:59:45,433 - INFO - [Epoch 1 | Idx: 91 | Optim Step: 46 | Loss: 1.3251]\n",
      "2025-07-08 04:59:48,784 - INFO - [Epoch 1 | Idx: 93 | Optim Step: 47 | Loss: 0.5689]\n",
      "2025-07-08 04:59:52,083 - INFO - [Epoch 1 | Idx: 95 | Optim Step: 48 | Loss: 1.3344]\n",
      "2025-07-08 04:59:55,391 - INFO - [Epoch 1 | Idx: 97 | Optim Step: 49 | Loss: 1.3080]\n",
      "2025-07-08 04:59:58,668 - INFO - [Epoch 1 | Idx: 99 | Optim Step: 50 | Loss: 1.6426]\n",
      "2025-07-08 05:00:01,965 - INFO - [Epoch 1 | Idx: 101 | Optim Step: 51 | Loss: 1.6756]\n",
      "2025-07-08 05:00:05,262 - INFO - [Epoch 1 | Idx: 103 | Optim Step: 52 | Loss: 1.5948]\n",
      "2025-07-08 05:00:08,534 - INFO - [Epoch 1 | Idx: 105 | Optim Step: 53 | Loss: 0.4490]\n",
      "2025-07-08 05:00:11,845 - INFO - [Epoch 1 | Idx: 107 | Optim Step: 54 | Loss: 1.3940]\n",
      "2025-07-08 05:00:15,172 - INFO - [Epoch 1 | Idx: 109 | Optim Step: 55 | Loss: 0.4774]\n",
      "2025-07-08 05:00:18,444 - INFO - [Epoch 1 | Idx: 111 | Optim Step: 56 | Loss: 0.5261]\n",
      "2025-07-08 05:00:21,759 - INFO - [Epoch 1 | Idx: 113 | Optim Step: 57 | Loss: 0.9556]\n",
      "2025-07-08 05:00:25,078 - INFO - [Epoch 1 | Idx: 115 | Optim Step: 58 | Loss: 0.2205]\n",
      "2025-07-08 05:00:28,404 - INFO - [Epoch 1 | Idx: 117 | Optim Step: 59 | Loss: 1.3891]\n",
      "2025-07-08 05:00:31,705 - INFO - [Epoch 1 | Idx: 119 | Optim Step: 60 | Loss: 0.9201]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f74e0504c94d77bd1a71c1d1c835e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "\n",
    "        with autocast(device_type = 'cuda', dtype = torch.bfloat16):\n",
    "            outputs = quantized_dora_base_model(**batch)\n",
    "            loss = outputs.loss / gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Accumulate Grads and step optimizer and log train-loss.\n",
    "        if (idx+1) % gradient_accumulation_steps == 0:\n",
    "            clip_grad_norm_(quantized_dora_base_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            logger.info(f\"[Epoch {epoch+1} | Idx: {idx} | Optim Step: {global_step} | Loss: {loss.item():.4f}]\")\n",
    "\n",
    "            # Evaluation loop\n",
    "            if global_step % 60 == 0:\n",
    "                avg_val_loss = do_validation()\n",
    "                logger.info(f\"Validation Loss at: {idx+1} -> {avg_val_loss:.4f}\\n\")\n",
    "    \n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    quantized_dora_base_model.save_pretrained(os.path.join(saveDir, 'PaliGemma-MultiDomain-QDORA-chkpt-1500-16R.pt'))\n",
    "                    logger.info(f\"***** Checkpoint Saved *****\\n\")\n",
    "                    best_val_loss = avg_val_loss\n",
    "            \n",
    "    logger.info(f\"Epoch {epoch+1} completed. Avg loss: {total_loss / len(train_loader):.4f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261c270-7eb5-4c85-abbb-3b156050b05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd077b-cde9-4473-afa3-15e711f39452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
